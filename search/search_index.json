{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"notes/A%20bit%20of%20probability%20theory/","title":"A bit of probability theory","text":""},{"location":"notes/A%20bit%20of%20probability%20theory/#cdf-and-pdf","title":"CDF and PDF","text":""},{"location":"notes/A%20bit%20of%20probability%20theory/#definitions","title":"Definitions","text":"<p>The cumulative distribution function (cdf) is the probability that a random variable, \\(X\\), will take a value less or equal to \\(x\\).</p> \\[P(x) = P_r \\{ X \\le x \\}\\] <p>\\(P(x)\\) can also be written as \\(F(x)\\)</p> <p>The probability density function (pdf) is the probability that a random variable, \\(X\\), will take a value \\(x\\). In the case of continuous values, the pdf represent the probability per unit length that a random variable, \\(X\\), will be closer to the sample \\(x\\) compared to the other sample.</p> <p>The cdf can also be expressed as the probability of all the event where \\(X\\) is less or equal to \\(x\\) which can be expressed with the pdf:</p> \\[P(x) = \\int_0^x p(X)dX\\] <ul> <li>\\(p(X)\\) is the pdf of the event \\(X\\)</li> <li>\\(X\\) is a random event</li> <li>\\(dX\\) is the rate of change of the random event \\(X\\)</li> </ul> <p>Since we can expressed the cdf with the pdf, we use it to express in return the pdf relative to the cdf:</p> \\[ p(x) = \\frac{dP}{dx}(x)\\] <p>If we want to compute the probability that a random variable \\(X\\) is in the interval \\([\\alpha, \\beta]\\), we can expressed it with the following relationship</p> \\[P_r \\{\\alpha \\le X \\le \\beta \\} = \\int_\\alpha^\\beta p(x)dx = P(\\beta) - P(\\alpha)\\]"},{"location":"notes/A%20bit%20of%20probability%20theory/#multidimensional-vector","title":"Multidimensional vector","text":"<p>For multidimensional random vector \\((X^1, \\dotsc, X^s)\\), we can use the joint cumulative distribution function</p> \\[P(x^1, \\dotsc, x^s) = P_r \\{ X^i \\le x^i \\text{ for all } i = 1, \\dotsc, s \\}\\] <p>and the join distribution function</p> \\[p(x^1, \\dotsc, x^s) = \\frac{ \\partial^s P }{\\partial x^1 \\dotsb \\partial x^s}(x^1, \\dotsc, x^s)\\] <p>For any Lebesgue measurable subset \\(D\\subseteq\\mathbb{R}^s\\), we have the following relationship:</p> \\[P_r \\{ x \\in D \\} = \\int_D p(x_1, \\dotsc, x_s) dx^1 \\dotsb dx^s\\] Lebesgue measure <p>explain what it is</p> <p>More generally, for a random variable \\(X \\in \\Omega\\), its probability measure (also known as a probability distribution or distribution) is a measure function \\(P\\) such that for any measurable set \\(D\\subseteq\\Omega\\), we have</p> \\[P(D) = P_r \\{ X \\in D \\}\\] <p>A probability measure must satisfy \\(P(\\Omega) = 1\\)</p> <p>The probability that \\(X \\in D\\) can be obtained by integrating \\(p(x)\\) over the given region \\(D\\) using the Radon-Nikodym theorem.</p> \\[P(D) = \\int_D p(x) d\\mu(x)\\] Radon-Nikodym theorem <p>The Radon\u2013Nikodym theorem involves a measurable space \\((X, \\Sigma)\\) on which two \\(\\sigma\\)-finite measures are defined, \\(\\mu\\) and \\(\\nu\\). It states that, if \\(\\nu \\ll \\mu\\) (that is, if \\(\\nu\\) is absolutely continuous with respect to \\(\\mu\\)), then there exists a \\(\\Sigma\\)-measurable function \\(f(X) \\in \\mathbb{R}^+\\) such that for any measurable set \\(D \\subseteq X\\)</p> \\[v(D) = \\int_D f(X) d\\mu\\] <p>The can then derived the last equation to get the density function \\(p\\).</p> \\[p(x) = \\frac{dP}{d\\mu}(x)\\]"},{"location":"notes/A%20bit%20of%20probability%20theory/#expected-value-and-variance","title":"Expected value and variance","text":""},{"location":"notes/A%20bit%20of%20probability%20theory/#expected-value","title":"Expected value","text":"<p>The expected value of a random variable with finite number of outcomes is a weighted average of all the possible outcomes. For a continuum of possible outcomes, the expected value is defined by integration. The expected value or expectation of a random variable \\(Y = f(X)\\) is defined as</p> \\[E[Y] = \\int_\\Omega f(x)p(x)d\\mu(x)\\] <p>Rendering paper tend to simplify this equation by removing \\(p(x)\\)</p> <p>show the simplification</p>"},{"location":"notes/A%20bit%20of%20probability%20theory/#variance","title":"Variance","text":"<p>The variance is a measure of dispersion which means it is a measure of how far a set of numbers is spread out from their average value.</p> \\[V[Y] = E \\left[(Y - E[Y])^2 \\right]\\] <p>It is assume that the expected value and variance of every random variable exist (i..e. the corresponding integral is finite).</p>"},{"location":"notes/A%20bit%20of%20probability%20theory/#standard-deviation","title":"Standard deviation","text":"<p>The standard deviation of a random variable (also known as the root mean square error), which is simply the square root of its variance:</p> \\[\\sigma[Y] = \\sqrt{V[Y]}\\]"},{"location":"notes/A%20bit%20of%20probability%20theory/#properties","title":"Properties","text":"<p>For any constant \\(\\alpha\\):</p> <ul> <li> \\[E[aY] = aE[Y]\\] </li> <li> \\[V[aY] = a^2 V[Y]\\] </li> </ul> <p>For any random variables \\(Y_1, \\dotsc , Y_N\\):</p> <ul> <li> \\[E \\left[ \\sum_{i=1}^N Y_i \\right] = \\sum_{i=1}^N E[Y_i]\\] </li> </ul> <p>The following identity holds only if the variables \\(Y_i\\) are independent:</p> <ul> <li> \\[V \\left[\\sum_{i=1}^N Y_i \\right] = \\sum_{i=1}^N V [Y_i]\\] </li> </ul> <p>Simplification of the variance</p> <p>From these rules, we can derive a simpler expression for the variance (remember that \\(E[Y]\\) is a constant)</p> \\[V[Y] = E \\left[(Y - E[Y])^2 \\right]\\] \\[V[Y] = E \\left[Y^2 - 2Y \\times E[Y] + E[Y]^2 \\right]\\] \\[V[Y] = E[Y^2] - E[2Y \\times E[Y]] + E[E[Y]^2]\\] \\[V[Y] = E[Y^2] - 2E[Y]^2 + E[Y]^2\\] \\[V[Y] = E[Y^2] - E[Y]^2\\]"},{"location":"notes/A%20bit%20of%20probability%20theory/#conditional-and-marginal-densities","title":"Conditional and marginal densities","text":"<p>https://machinelearningmastery.com/joint-marginal-and-conditional-probability-for-machine-learning/ https://en.wikipedia.org/wiki/Conditional_probability_distribution https://study.com/learn/lesson/marginal-vs-conditional-probability-distributions-differences-rules-examples.html</p>"},{"location":"notes/notes/","title":"Robust Monte Carlo Methods For Light Transport Simulation","text":""},{"location":"notes/notes/#chapter-1-introduction","title":"Chapter 1: Introduction","text":"<p>The focus is set on unbiased, view dependent, Monte Carlo algorithms.</p> <p>A view-independent algorithm is an algorithm that computes an intermediate representation of the solution, from which we can create arbitrary views quickly. Any other algorithm is view-dependant.</p> <p>Put it simply, an unbiased estimator computes the correct answer, on average. A biased estimator computes the wrong answer on average. However, if a biased estimator is consistent, then the average error can be made arbitrarily small by increasing the sample size.</p> <p>The rainbow effect created by a light going through a transmission is called a <code>dispersion</code></p>"},{"location":"notes/notes/#chapter-2-monte-carlo-integration","title":"Chapter 2: Monte Carlo Integration","text":""},{"location":"notes/notes/#probability-theory","title":"Probability theory","text":""},{"location":"notes/notes/#cdf-and-pdf-functions","title":"CDF and PDF functions","text":"<p>Cumulative distribution function (cdf) of a real-valued random variable \\(X\\) is defined as:</p> \\[P(x) = P_r \\{ X \\le x \\} = \\int_0^x p(X)dX\\] <p>The cdf is the sum of the probability that an event \\(X\\) is less or equal to \\(x\\)</p> <p>\\(dx\\) represent the volume integrated for the integral</p> <p>\\(P(x)\\) can also be written as \\(F(x)\\)</p> <p>and the corresponding probability density function (also known as pdf) is:</p> \\[ p(x) = \\frac{dP}{dx}(x)\\] <p>\\(p(x)\\) represent the rate of change of the cdf for an event \\(x\\).</p> <p>For a function \\(f(x) = y\\), if we define \\(F\\) as the sum of all the values of \\(f(x)\\), therefore \\(f(x) = y = \\frac{dF}{dx}(x)\\).</p> <p>This leads to the following relationship:</p> \\[P_r \\{\\alpha \\le X \\le \\beta \\} = \\int_\\alpha^\\beta p(x)dx = P(\\beta) - P(\\alpha)\\] <p>This equation is just an extension of the cdf equation if you think of \\(P(x) = P_r \\{ 0 \\le X \\le x \\}\\) where \\(\\alpha = 0\\) and \\(\\beta = x\\).</p> <p>The corresponding notions for a multidimensional random vector \\((X^1, \\dotsc, X^s)\\) are the joint cumulative distribution function:</p> \\[P(x^1, \\dotsc, x^s) = P_r \\{ X^i \\le x^i \\text{ for all } i = 1, \\dotsc, s \\}\\] <p>and the joint density function:</p> \\[p(x^1, \\dotsc, x^s) = \\frac{ \\partial^s P }{\\partial x^1 \\dotsb \\partial x^s}(x^1, \\dotsc, x^s) = \\prod_{i = 1}^s \\frac{\\partial P}{\\partial x^i}dx^i\\] <p>Jacobien</p> <p>so that we have the relationship:</p> \\[P_r \\{ x \\in D \\} = \\int_D p(x_1, \\dotsc, x_s) dx^1 \\dotsb dx^s\\] <p>for any Lebesgue measurable subset \\(D \\sub \\reals^s\\).</p> <p>The 3 equations above are just an evolution of the first ones with \\(x^1, \\dotsc, x^s\\) instead of \\(X\\)</p> <p>More generally, for a random variable \\(X\\) with values in an arbitrary domain \\(\\Omega\\), its probability measure (also known as a probability distribution or distribution) is a measure function \\(P\\) such that:</p> \\[P(D) = P_r \\{ X \\in D \\}\\] <p>for any measurable set \\(D \\sub \\Omega\\). In particular, a probability measure must satisfy \\(P(\\Omega) = 1\\).</p> <p>The corresponding density function \\(p\\) is defined as the Radon-Nikodym derivative</p> \\[p(x) = \\frac{dP}{d\\mu}(x)\\] <p>\\(d\\mu\\) replaced \\(dx\\)</p> <p>\\(\\mu\\) is a measure of density corresponding on the volume integrated (i.e. area, solid angle, etc...)</p> <p>which is simply the function \\(p\\) that satisfies</p> \\[P(D) = \\int_D p(x) d\\mu(x)\\] <p>The probability that \\(X \\in D\\) can be obtained by integrating \\(p(x)\\) over the given region \\(D\\).</p>"},{"location":"notes/notes/#expected-value-and-variance","title":"Expected value and variance","text":"<p>The expected value or expectation of a random variable \\(Y = f(X)\\) is defined as</p> \\[E[Y] = \\int_\\Omega f(x)p(x)d\\mu(x)\\] <p>The expected value of \\(Y\\) is equal to the sum of all the value of \\(f(x) \\in \\Omega\\) multiplied by its pdf (\\(p(x)\\)) and by the derivative of the measure of density (\\(d\\mu(x)\\)).</p> <p>Rendering paper tend to simplify this equation by removing \\(p(x)\\)</p> <p>while its variance is</p> \\[V[Y] = E \\left[(Y - E[Y])^2 \\right]\\] <p>It is assume that the expected value and variance of every random variable exist (i..e. the corresponding integral is finite).</p> <p>The variance of \\(Y\\) is equal to the expected value of the square root of, \\(Y\\) minus the expected value of \\(Y\\).</p> <p>Another useful quantity is the standard deviation of a random variable, which is simply the square root of its variance:</p> \\[\\sigma[Y] = \\sqrt{V[Y]}\\] <p>This is also known as the root mean square (RMS) error.</p>"},{"location":"notes/notes/#properties","title":"Properties","text":"<p>For any constant \\(\\alpha\\):</p> <ul> <li> \\[E[aY] = aE[Y]\\] </li> <li> \\[V[aY] = a^2 V[Y]\\] </li> </ul> <p>For any random variables \\(Y_1, \\dotsc , Y_N\\):</p> <ul> <li> \\[E \\left[ \\sum_{i=1}^N Y_i \\right] = \\sum_{i=1}^N E[Y_i]\\] </li> </ul> <p>The following identity holds only if the variables \\(Y_i\\) are independent:</p> <ul> <li> \\[V \\left[\\sum_{i=1}^N Y_i \\right] = \\sum_{i=1}^N V [Y_i]\\] </li> </ul> <p>Notice that from these rules, we can derive a simpler expression for the variance:</p> <ul> <li> \\[V[Y] = E \\left[(Y - E[Y])^2 \\right] = E \\left[Y^2 \\right] - E[Y]^2\\] </li> </ul>"},{"location":"notes/notes/#conditional-and-marginal-densities","title":"Conditional and marginal densities","text":"<p>Let \\(X \\in \\Omega_1\\) and \\(Y \\in \\Omega_2\\) be a pair of random variables, so that:</p> \\[(X, Y) \\in \\Omega\\] <p>where \\(\\Omega = \\Omega_1 \\times \\Omega_2\\).</p> <p>Let \\(P\\) be the joint probability measure of \\((X, Y)\\), so that \\(P(D)\\) represents the probability that \\((X, Y) \\in D\\) for any measurable subset \\(D \\sub \\Omega\\). Then the corresponding joint density function \\(p(x, y)\\) satisfies</p> \\[P(D) = \\int_D p(x, y) d\\mu_1(x) d\\mu_2(y)\\] <p>where \\(\\mu_1\\) and \\(\\mu_2\\) are measures on \\(\\Omega_1\\) and \\(\\Omega_2\\) respectively.</p> <p>The marginal density function of X is now defined as</p> \\[p(x) = \\int_{\\Omega_2} p(x, y)dy\\] <p>Reminder that \\(dy\\) is the simplified notation of the measure function notation \\(d\\mu(y)\\)</p> <p>while the conditional density function \\(p(x|y)\\) is defined as</p> \\[p(x|y) = \\frac{p(x, y)}{p(x)}\\] <p>The marginal density \\(p(y)\\) and conditional density \\(p(x | y)\\) are defined in a similar way, leading to the useful identity:</p> \\[p(x, y) = p(y | x) p(x) = p(x | y) p(y)\\] <p>Another important concept is the conditional expectation of a random variable \\(G = g(X, Y)\\), defined as</p> \\[E \\left[ G | x \\right] \\int_{\\Omega_2} g(x, y) p(y|x) dy = \\frac{\\int g(x, y) p(x, y) dy}{\\int p(x, y) dy}\\] <p>\\(E_Y[G]\\) is used for conditional expectation, to emphasizes the fact that Y is the random variable whole density function is being integrated.</p> <p>There is a very useful expression for the variance of G in terms of its conditional expectation and variance, namely</p> \\[V[G] = E_X V_Y G + V_X E_Y G\\] <p>\\(V[G]\\) is the mean of the conditional variance, plus the variance of the conditional mean</p>"},{"location":"notes/notes/#basic-monte-carlo-integration","title":"Basic Monte Carlo integration","text":"<p>The idea of Monte Carlo integration is to evaluate the integral:</p> \\[I = \\int_\\Omega f(x) d\\mu(x)\\] <p>using random sampling. It is done by independently sampling \\(N\\) points \\(X^1, \\dotsc, X^s\\) according to a density function \\(p\\), and then computing the estimate</p> \\[F_N = \\frac{1}{N} \\sum_{i = 1}^{N} \\frac{f(X_i)}{p(X_i)}\\] <p>It used \\(F_N\\) rather than \\(I\\) to emphasize that the result is a random variable</p> <p>Monte Carlo integration converges at a rate of \\(O(N^{-1/2})\\) in any dimension</p> <p>For further details:</p> <ul> <li>2.4.1 convergence rates: proof of the convergence rates</li> </ul>"},{"location":"notes/notes/#monte-carlo-estimator","title":"Monte Carlo estimator","text":"<p>We define \\(Q\\) (called estimand), as the value of a given integral.</p>"},{"location":"notes/notes/#properties_1","title":"Properties","text":"<ul> <li>The quantity \\(F_N - Q\\) is called the <code>error</code>, and its expected value is called the <code>bias</code>:</li> </ul> \\[\\beta[F_N] = E[F_N - Q]\\] <ul> <li>an estimator is called <code>unbiased</code> if \\(\\beta[F_N] = 0\\) for all sample sizes \\(N\\) which means</li> </ul> \\[E[F_N] = Q \\text{ for all } N \\ge 1\\] <ul> <li>an estimator is called <code>consistent</code> if the error \\(F_N - Q\\) goes to zero with probability one</li> </ul> \\[P_r \\left\\{ \\lim_{ N \\to \\infty} F_N = Q \\right\\} = 1\\] <ul> <li>another way to say it, it that for an estimator to be consistent, the bias and variance both have to go to zero as \\(N\\) is increased</li> </ul> \\[\\lim_{N \\to \\infty} \\beta[F_N] = \\lim_{N \\to \\infty} V[F_N] = 0\\] <ul> <li>an unbiased estimator is consistent as long as its variance decrease to zero as \\(N\\) goes to infinity</li> </ul> <p>To not confuse with the fact of being unbiased which means that the result of the integral does not have bias for all samples \\(N\\).</p>"},{"location":"notes/notes/#unbiased-estimators","title":"Unbiased estimators","text":"<p>Typically the goal is to minimize the mean squared error (\\(MSE\\)), defined by</p> \\[MSE[F] = E[(F - Q)^2]\\] <p>Which can be simplified in (Veach p.44 for how to simplify)</p> \\[MSE[F] = V[F] + \\beta[F]^2\\] <p>For unbiased estimators, we can simplified it even further since \\(\\beta[F] = 0\\)</p> \\[MSE[F] = V[F] = E[(F - E[F])^2]\\] <p>\\(\\beta\\) is non-trivial to compute, which make computing the error difficult for biased estimator. Thus, error estimates are easier to obtain for unbiased estimators. </p> <p>Letting \\(Y_1, \\dotsc, Y_N\\) be independent samples of an unbiased estimator \\(Y\\), and letting</p> \\[F_N = \\frac{1}{N}\\sum_{i = 1}^N Y_i\\] <p>as before, then the quantity is</p> \\[\\hat{V}[F_N] = \\frac{1}{N-1} \\left\\{ \\left( \\frac{1}{N} \\sum_{i = 1}^N Y_i^2 \\right) - \\left( \\frac{1}{N} \\sum_{i = 1}^N Y_i \\right)^2 \\right\\}\\] <p>Look for the simpler version of the variance</p> <p>The hat signal that it is relative to an estimator</p> <p>The error of an unbiased estimator can be made as small as desired since</p> \\[V[F_N] = V[F_1] / N\\] <p>The goal is to find an estimator whose variance and running time are both small. This is describe by the efficiency of a Monte Carlo estimator:</p> \\[\\epsilon[F] = \\frac{1}{V[F]T[F]}\\] <p>where \\(T[F]\\) is the time required to evaluate \\(F\\).</p>"},{"location":"notes/notes/#variance-reduction-analytic-integration","title":"Variance reduction: Analytic integration","text":"<p>The techniques developed to design efficient estimators are often called <code>variance reduction methods</code>. These methods are usually grouped into categories base around 4 main ideas:</p> <ul> <li> <p><code>analytically</code> integrating a function that is similar to the integrand</p> </li> <li> <p><code>uniformly</code> placing sample points across the integration domain</p> </li> <li> <p><code>adaptively</code> controlling the sample density based on information gathered during sampling</p> </li> <li> <p>combining samples from two or more estimators whose values are correlated</p> </li> </ul>"},{"location":"notes/notes/#use-of-expected-values","title":"Use of expected values","text":"<p>One way to reduce variance is to reduce the dimension of the sample space, by integrating analytically with respect to one or more variables of the domain. It consists of replacing an estimator of the form</p> \\[F = f(X, Y) / p(X, Y)\\] <p>with one of the form</p> \\[F' = f'(X) / p(X)\\] <p>where \\(f'(x)\\) and \\(p(x)\\) are defined by</p> \\[f'(x) = \\int f(x, y) dy\\] \\[p(x) = \\int p(x, y) dy\\] <p>This formulas explain the relationship between \\(f'(x)\\), \\(p(x)\\) and respectively \\(f(x, y)\\), \\(p(x, y)\\).</p> <p>Thus, to apply this technique, we must be able to integrator both \\(\\int\\) and \\(p\\) with respect to y.</p> <p>The use of expected values is the preferred variance reduction technique, as long as it is not too expensive to evaluate and sample the analytically integrated quantities.</p> <p>Note that if expected values are used for only one part of a larger calculation, then variance can increase.</p>"},{"location":"notes/notes/#importance-sampling","title":"Importance sampling","text":"<p>Importance sampling refers to the principle of choosing a density function \\(p\\) that is similar to the integrand \\(\\int\\).</p> <p>The best choice is to let \\(p(x) = cf(x)\\), where the constant of proportionality, to ensure \\(p\\) integrates to one, is</p> \\[c = \\frac{1}{\\int_{\\Omega}f(y)d\\mu(y)}\\] <p>This leads to an estimator with zero variance, since</p> \\[F = \\frac{f(X)}{p(X)} = \\frac{f(X)}{cf{X}} = \\frac{1}{c}\\] <p>for all sample points \\(X\\).</p> <p>Not practical since we must already know the value of the desired integral to compute the constant</p> <p>Importance sampling is one of the most useful and powerful techniques of Monte Carlo integration. </p>"},{"location":"notes/notes/#control-variates","title":"Control variates","text":"<p>The idea behind control variates, is to find a function \\(g\\) that can be integrated analytically and is similar to the integrand, and then subtract it. The integral is rewritten as</p> \\[I = \\int_{\\Omega} g(x) d\\mu(x) + \\int_{\\Omega} f(x) - g(x) d\\mu(x)\\] <p>and then sampled with an estimator of the form</p> \\[F = \\int_{\\Omega} g(x) d\\mu(x) + \\frac{1}{N} \\sum_{i = 1}^{N} \\frac{f(X_i - g(X_i))}{p(X_i)}\\] <p>where the value of the first integral is known exactly.</p> <p>The estimator will have a lower variance than the basic estimator whenever</p> \\[V\\left[ \\frac{f(X_i) - g(X_i)}{p(X_i)} \\right] \\le V \\left[ \\frac{f(X_i)}{p(X_i)} \\right]\\] <p>Given a function \\(g\\) that is an approximation to \\(f\\), we must decide whether to use it as a control variate or as a density function for importance sampling.</p> <p>It is possible that either one of the choice could be the best</p> <p>In general, if:</p> <ul> <li> <p>\\(f - g\\) is nearly a constant function, then \\(g\\) should be used as a control variate</p> </li> <li> <p>\\(f/g\\) is nearly a constant, then \\(g\\) should be used for importance sampling</p> </li> </ul> <p>Control variates have very few application in graphics currently. This technique can produce negative sample values, even for an integrand that is strictly positive. This can lead to large relative errors for integrals whose true value is close to zero.</p> <p>On the other hand, the method is straightforward to apply, and can potentially give a modest variance reduction at little cost.</p>"},{"location":"notes/notes/#variance-reduction-uniform-sample-placement","title":"Variance reduction: Uniform sample placement","text":"<p>Another important strategy for reducing variance is to ensure that samples are distributed more or less uniformly over the domain.</p> <p>This technique usually assumed that the domain is the \\(s\\)-dimensional unit cube \\([0, 1]^s\\). The other domain can be handled by defining the appropriate transformation of the form \\(T: [0, 1]^s \\rightarrow \\Omega\\).</p> <p>Note that by choosing different mapping \\(T\\), the transformed samples can be given different density functions</p>"},{"location":"notes/notes/#stratified-sampling","title":"Stratified sampling","text":"<p>The idea of stratified sampling is to subdivide the domain \\(\\Omega\\) into several non-overlapping regions \\(\\Omega_1, \\dotsc, \\Omega_m\\) such that</p> \\[\\bigcup_{i = 1}^n \\Omega_i = \\Omega\\] <p>The union of all the regions \\(\\Omega_i\\) from 0 to \\(n\\) is equal to the domain \\(\\Omega\\) </p> <p>Each region \\(\\Omega_i\\) is called a stratum. A fixed number of samples \\(n_i\\), is taken within each \\(\\Omega_i\\), according to some given density function \\(p\\).</p> <p>Stratified sampling is a useful, inexpensive variance reduction technique. It is mainly effective for low dimensional integration problems where the integrand is reasonably well-behaved.</p>"},{"location":"notes/notes/#latin-hypercube-sampling","title":"Latin hypercube sampling","text":"<p>The idea of latin hypercube sampling is to subdivide the domain \\([0, 1]^s\\) into \\(N\\) sub-intervals along each dimension, and to ensure that one sample lies in each sub-interval.</p> \\[X_i^j = \\frac{\\pi_j(i) - U_{i, j}}{N}\\] <ul> <li> <p>\\(X_i^j\\) denotes the \\(j\\)-th coordinate of the sample \\(X_i\\)</p> </li> <li> <p>\\(U_{i, j}\\) are independent and uniformly distributed on \\([0, 1]\\)</p> </li> </ul> <p>In two dimensions, the sample pattern corresponds to the occurrences of a single symbol in a Latin square (i.e an \\(N \\times N\\) array of \\(N\\) symbols such that no symbol appears twice in the same row or column).</p>"},{"location":"notes/notes/#orthogonal-array-sampling","title":"Orthogonal array sampling","text":""},{"location":"notes/notes/#quasi-monte-carlo-methods","title":"Quasi-Monte Carlo methods","text":""},{"location":"notes/notes/#variance-reduction-adaptive-sample-placement","title":"Variance reduction: Adaptive sample placement","text":""},{"location":"notes/notes/#adaptive-sampling","title":"Adaptive sampling","text":"<p>do some research</p>"},{"location":"notes/notes/#russian-roulette-and-splitting","title":"Russian roulette and splitting","text":"<p>Their purpose is to decrease the sample density where the integrand is small and increase it where the integrand is large. These technique do not introduce bias.</p>"},{"location":"notes/notes/#russian-roulette","title":"Russian roulette","text":"<p>It is applied to estimators that are the sum of many terms: \\(F = F_1 + \\dotsc + F_N\\). This technique solve the issue where the contributions are very small, and yet as expensive to evaluate as the others contributions. The idea of russian roulette is to randomly skip most of the evaluations associated with small contributions, by replacing these \\(F_i\\) with new estimators of the form</p> \\[F_i' = \\begin{cases} \\frac{1}{q_i}F_i &amp; \\quad \\text{with probability } q_i \\\\ 0 &amp; \\quad \\text{otherwise} \\end{cases}\\] <p>The evaluation probability \\(q_i\\) is chosen for each \\(F_i\\) separately, based on some convenient estimate of its contribution.</p> <p>The estimator \\(F_i'\\) is unbiased whenever \\(F_i\\).</p> <p>This technique increases variance. Russian roulette can still increase efficiency by reducing the average time required to evaluate \\(F\\).</p> <p>Suppose that each \\(F_i\\) represents the contribution of a particular light source to the radiance reflected from a surface. To reduce the number of visibility tests using Russian roulette, we first compute a tentative contribution \\(t_i\\) for each \\(F_i\\) ignoring blockers. The a fixed threshold \\(\\delta\\) is typically chosen, and the probabilities \\(q_i\\) are set to</p> \\[q_i = \\min(1, t_i / \\delta)\\] <p>Thus contribution larger than \\(\\delta\\) are always evaluated, while smaller contribution are randomly skipped in a way that does not cause bias.</p>"},{"location":"notes/notes/#splitting","title":"Splitting","text":"<p>Russian roulette is closely related to splitting, a technique in which an estimator \\(F_i\\) is replaced by one of the form</p> \\[F_i' = \\frac{1}{k} \\sum_{j = 1}^k F_{i, j}\\] <p>where the \\(F_{i, j}\\) are independent samples from \\(F\\). </p>"},{"location":"notes/notes/#variance-reduction-correlated-estimators","title":"Variance reduction: Correlated estimators","text":""},{"location":"notes/notes/#antithetic-variates","title":"Antithetic variates","text":""},{"location":"notes/notes/#regression-methods","title":"Regression methods","text":""},{"location":"notes/notes/#chapter-3-radiometry-and-light-transport","title":"Chapter 3: Radiometry and Light Transport","text":"<p>manifold?</p> <p>phase space?</p> <p>trajectory space?</p> <p>| Term | Description |</p> <p>|:-:|:-:|</p> <p>| \\(\\mathcal{M}\\) | union of a finite set of surfaces in \\(\\reals^3\\) (scene geometry)|</p> <p>| \\(\\sigma\\) | solid angle |</p> <p>| \\(\\sigma^\\perp_x\\)| projected solid angle measure on surface x |</p>"},{"location":"notes/notes/#chapter-4-a-general-operator-formulation-of-light-transport","title":"Chapter 4: A General Operator Formulation of Light Transport","text":""},{"location":"notes/notes/#chapter-8-a-path-integral-formulation-of-light-transport","title":"Chapter 8: A Path Integral Formulation of Light Transport","text":""},{"location":"notes/notes/#chapter-9-multiple-importance-sampling","title":"Chapter 9: Multiple Importance Sampling","text":""},{"location":"notes/notes/#chapter-10-bidirectional-path-tracing","title":"Chapter 10: Bidirectional Path Tracing","text":""},{"location":"notes/notes/#chapter-11-metropolis-light-transport","title":"Chapter 11: Metropolis Light Transport","text":""},{"location":"notes/notes/#links","title":"Links","text":"<ul> <li> <p>Robust Monte Carlo Methods For Light Transport Simulation, Eric Veach</p> </li> <li> <p>Monte Carlo theory, methods and examples, Art Owen</p> </li> </ul>"}]}